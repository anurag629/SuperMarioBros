{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mario Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym_super_mario_bros==7.3.0\n",
      "  Using cached gym_super_mario_bros-7.3.0-py2.py3-none-any.whl (198 kB)\n",
      "Collecting nes_py\n",
      "  Using cached nes_py-8.2.1.tar.gz (77 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: gym>=0.17.2 in c:\\users\\anurag verma\\anaconda3\\lib\\site-packages (from nes_py) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\anurag verma\\anaconda3\\lib\\site-packages (from nes_py) (1.23.5)\n",
      "Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in c:\\users\\anurag verma\\anaconda3\\lib\\site-packages (from nes_py) (1.5.21)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in c:\\users\\anurag verma\\anaconda3\\lib\\site-packages (from nes_py) (4.64.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\anurag verma\\anaconda3\\lib\\site-packages (from gym>=0.17.2->nes_py) (4.11.3)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\anurag verma\\anaconda3\\lib\\site-packages (from gym>=0.17.2->nes_py) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\anurag verma\\anaconda3\\lib\\site-packages (from gym>=0.17.2->nes_py) (2.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\anurag verma\\anaconda3\\lib\\site-packages (from tqdm>=4.48.2->nes_py) (0.4.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\anurag verma\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.0->gym>=0.17.2->nes_py) (3.8.0)\n",
      "Building wheels for collected packages: nes_py\n",
      "  Building wheel for nes_py (setup.py): started\n",
      "  Building wheel for nes_py (setup.py): finished with status 'done'\n",
      "  Created wheel for nes_py: filename=nes_py-8.2.1-cp39-cp39-win_amd64.whl size=45819 sha256=7e379aa5587b8e944c4d76c4cb56747e688181995e0c8bddf98d130aed9c939a\n",
      "  Stored in directory: c:\\users\\anurag verma\\appdata\\local\\pip\\cache\\wheels\\c6\\e1\\4b\\dbbd5d4a46ad80c0149d5671edb272c728c130e4d5750ca1d2\n",
      "Successfully built nes_py\n",
      "Installing collected packages: nes_py, gym_super_mario_bros\n",
      "Successfully installed gym_super_mario_bros-7.3.0 nes_py-8.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gym_super_mario_bros==7.3.0 nes_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the game\n",
    "import gym_super_mario_bros\n",
    "# Import the Joypad wrapper\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "# Import the SIMPLIFIED controls\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use of the `make()` function to setup the simulation\n",
    "\n",
    "* The `make()` function takes one argument of type str, which is the name of the RL task.\n",
    "* The RL task and its simulation is usually called environment in RL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup game\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line imports the Super Mario Bros environment using the gym_super_mario_bros.make() function. This function takes the name of the game as an argument, in this case, \"SuperMarioBros-v0\". The environment represents the game and provides an interface to interact with it.\n",
    "\n",
    "The second line wraps the environment with the JoypadSpace function, which allows the use of pre-defined actions for the game. The SIMPLE_MOVEMENT variable represents a set of simple actions that can be performed in the game, such as moving left or right, jumping, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(0, 255, (240, 256, 3), uint8)\n"
     ]
    }
   ],
   "source": [
    "# checking the environment\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code `print(env.observation_space)` is used to check the observation space of the Super Mario Bros environment that was previously set up.\n",
    "\n",
    "The observation space is a description of the state of the environment at any given time, and it represents what the agent can see and use to make decisions. The output of this code will typically be a description of the shape and type of the observation space, which can be a tuple or a Box object.\n",
    "\n",
    "For example, the output could be `(240, 256, 3)`, which means that the observation space is a 3-dimensional array of size 240x256 pixels, with 3 color channels (RGB).\n",
    "\n",
    "By knowing the observation space, an agent can use it to determine what actions to take based on what it sees in the environment, and how to represent the state of the environment in its internal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(7)\n"
     ]
    }
   ],
   "source": [
    "# checking the action space\n",
    "print(env.action_space)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The action space is a description of the possible actions that an agent can take in the environment. The output of this code will typically be a description of the type and shape of the action space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(0, 255, (240, 256, 3), uint8)\n",
      "Discrete(7)\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "# checking the environment\n",
    "print(env.observation_space)\n",
    "# checking the action space\n",
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = env.action_space.sample()\n",
    "action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code `action = env.action_space.sample()` generates a random action from the action space of the Super Mario Bros environment that was previously set up.\n",
    "\n",
    "The `env.action_space.sample()` method selects a random action from the action space. The output of this code will typically be an integer that represents the selected action.\n",
    "\n",
    "By generating a random action, an agent can explore the environment and learn more about how different actions affect the state and reward. However, random actions are usually not very effective for achieving high scores or completing tasks, and more sophisticated algorithms and strategies are needed to achieve good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NOOP'],\n",
       " ['right'],\n",
       " ['right', 'A'],\n",
       " ['right', 'B'],\n",
       " ['right', 'A', 'B'],\n",
       " ['A'],\n",
       " ['left']]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIMPLE_MOVEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use of the `reset()` function to reset the environment to its initial state.\n",
    "* After setup, you can usually inspect the environment anytime by calling the `render()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the environment\n",
    "env.reset()\n",
    "# render the environment\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a flag - restart or not\n",
    "done = True\n",
    "# Create a counter for the number of frames\n",
    "frame = 0\n",
    "# Create a counter for the number of episodes\n",
    "episode = 0\n",
    "\n",
    "# Loop through the episodes\n",
    "while True:\n",
    "    # Restart the game\n",
    "    if done:\n",
    "        # Reset the environment\n",
    "        state = env.reset()\n",
    "        # Increment the episode counter\n",
    "        episode += 1\n",
    "    # Render the environment\n",
    "    env.render()\n",
    "    # Take a random action\n",
    "    action = env.action_space.sample()\n",
    "    try:\n",
    "        # Get the next state, reward, done and info\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "    except ValueError:\n",
    "        next_state, reward, done = env.step(action)\n",
    "        info = None\n",
    "    # Increment the frame counter\n",
    "    frame += 1\n",
    "    # Print the number of frames and episodes\n",
    "    print('Frames: %s, Episodes: %s' % (frame, episode), end='\\r')\n",
    "\n",
    "# Close the environment\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code sets up a game environment using the `gym_super_mario_bros` library and creates a flag variable named `done`, a `frame` counter frame, and an `episode` counter episode. The program runs in an infinite loop that starts a new episode whenever the `done` flag is set to `True`. Inside the loop, the environment is rendered using the `env.render()` function, and a random action is selected from the action space using `env.action_space.sample()`. The selected action is applied to the environment using `env.step(action)`, and the resulting `next_state`, `reward`, `done`, and `info` variables are returned. The `frame` and `episode` counters are updated accordingly, and their values are printed to the console. The loop continues until the program is terminated. Finally, the environment is closed using `env.close()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
